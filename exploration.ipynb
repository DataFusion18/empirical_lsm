{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exploration\n",
    "\n",
    "## Todo\n",
    "\n",
    "- add more metrics\n",
    "    - mutual info score\n",
    "- multi variate output\n",
    "- table of results\n",
    "- Rhys: Compare the functional form of empirical models to that of LSMs, see where they differ\n",
    "    - multivariate functional form\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import xray\n",
    "import pandas as pd\n",
    "\n",
    "from numbers import Number\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pl.rcParams['figure.figsize'] = (12.0, 3)\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import mpld3\n",
    "#mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Perceptron, SGDRegressor, LogisticRegression, PassiveAggressiveRegressor\n",
    "from sklearn.svm import SVR, NuSVR  #, LinearSVR\n",
    "# from sklearn.neural_network import MultilayerPerceptronRegressor # This is from a pull request: https://github.com/scikit-learn/scikit-learn/pull/3939\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_vars = ['SWdown', 'Tair', 'LWdown', 'Wind', 'Rainf', 'PSurf', 'Qair']\n",
    "met_data = xray.open_dataset('/home/naught101/phd/data/PALS/datasets/met/TumbaFluxnet.1.4_met.nc')\n",
    "met_df = met_data.to_dataframe().reset_index(['x','y','z']).ix[:, met_vars]\n",
    "\n",
    "flux_vars = ['Qh', 'Qle', 'Rnet', 'NEE']\n",
    "flux_data = xray.open_dataset('/home/naught101/phd/data/PALS/datasets/flux/TumbaFluxnet.1.4_flux.nc')\n",
    "flux_df = flux_data.to_dataframe().reset_index(['x','y']).ix[:, flux_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flux_df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(met_df[0:3]).shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(f):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time.time()\n",
    "        #print(f.__name__, 'took: {:2.4f} sec'.format(te-ts))        \n",
    "        return (result, te-ts)\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def fit_pipeline(pipe, X, Y):\n",
    "    pipe.fit(X, Y)\n",
    "    \n",
    "    \n",
    "@timeit\n",
    "def get_pipeline_prediction(pipe, X):    \n",
    "    return(pipe.predict(X))\n",
    "\n",
    "\n",
    "def get_pipeline_name(pipe):\n",
    "    return(', '.join(pipe.named_steps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# METRICS\n",
    "metrics = OrderedDict()\n",
    "\n",
    "def rmse(obs, pred):\n",
    "    return(np.sqrt(np.mean((obs - pred)**2)))\n",
    "metrics.update({'rmse': rmse})\n",
    "\n",
    "def nme(obs, pred):\n",
    "    '''PLUMBER normalised mean error'''\n",
    "    return(np.sum(np.abs(obs - pred))/np.sum(np.abs(obs - np.mean(obs))))\n",
    "metrics.update({'nme': nme})\n",
    "\n",
    "def mbe(obs, pred):\n",
    "    '''PLUMBER mean bias error'''\n",
    "    return(np.sum(pred - obs)/len(obs))\n",
    "metrics.update({'mbe': mbe})\n",
    "\n",
    "def sd_diff(obs, pred):\n",
    "    '''PLUMBER standard deviation difference'''\n",
    "    return(abs(1 - np.std(pred)/np.std(obs)))\n",
    "metrics.update({'sd_diff': sd_diff})\n",
    "\n",
    "def corr(obs, pred):\n",
    "    return(np.corrcoef(obs, pred)[0,1])\n",
    "metrics.update({'corr': corr})\n",
    "\n",
    "def extreme_5(obs, pred):\n",
    "    '''PLUMBER 5th percentile difference'''\n",
    "    return(np.abs(np.percentile(pred, 5) - np.percentile(obs, 5)))\n",
    "metrics.update({'extreme_5': extreme_5})\n",
    "\n",
    "def extreme_95(obs, pred):\n",
    "    '''PLUMBER 95th percentile difference'''\n",
    "    return(np.abs(np.percentile(pred, 95) - np.percentile(obs, 95)))\n",
    "metrics.update({'extreme_95': extreme_95})\n",
    "\n",
    "# TODO: None of these make sense\n",
    "def skewness(obs, pred):\n",
    "    '''PLUMBER skewness'''\n",
    "    skewness = sum(((pred - np.mean(pred))/np.std(pred))**3)/len(pred)\n",
    "    return(skewness)\n",
    "metrics.update({'skewness': skewness})\n",
    "\n",
    "def kurtosis(obs, pred):\n",
    "    '''PLUMBER kurtosis'''\n",
    "    kurtosis = (sum(((pred - np.mean(pred))/np.std(pred))**4) - 3)/len(pred)\n",
    "    return(kurtosis)\n",
    "metrics.update({'kurtosis': kurtosis})\n",
    "\n",
    "def overlap(obs, pred):\n",
    "    '''PLUMBER overlap'''\n",
    "    overlap = np.sum(np.minimum(obs,pred))\n",
    "    return(overlap)\n",
    "metrics.update({'overlap': overlap})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = (np.random.rand(100), np.random.rand(100))\n",
    "[print(n,':', \"{:.3f}\".format(m(a,b))) for (n, m) in metrics.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_pipeline(pipe, X=met_df, Y=flux_df, y_var='Qh', name=None):\n",
    "    if name is None:\n",
    "        name = get_pipeline_name(pipe)\n",
    "\n",
    "    Y = np.array(Y[y_var])\n",
    "    \n",
    "    \n",
    "    train_len = (7*len(X)//10)\n",
    "    \n",
    "    # X_train, X_validate, Y_train, Y_validate = train_test_split(X, Y, train_size=0.7, random_state=0)\n",
    "    X_train = X[:train_len]\n",
    "    X_validate = X[train_len:]\n",
    "    Y_train = Y[:train_len]\n",
    "    Y_validate = Y[train_len:]\n",
    "    \n",
    "    metadata = OrderedDict({'name': name})  #, 'model': pipe.named_steps})\n",
    "    \n",
    "    metadata['t_fit'] = fit_pipeline(pipe, X_train, Y_train)[1]\n",
    "    (Y_pred, metadata['t_pred']) = get_pipeline_prediction(pipe, X_validate)\n",
    "    \n",
    "    #print(name)\n",
    "    #[print('\\t', k, ': ', v) for (k, v) in pipe.steps]\n",
    "    print(\"debug_shape: \", Y_pred.shape)\n",
    "    print('---')\n",
    "    if len(Y_pred.shape) > 1:\n",
    "        Y_pred = Y_pred[:,0]\n",
    "    \n",
    "    for (n, m) in metrics.items():\n",
    "        metadata[n] = m(Y_pred, Y_validate)\n",
    "    metadata['corr'] = np.corrcoef(Y_pred, Y_validate)[0,1]\n",
    "    [print('{:>10}:'.format(k), '{:.3f}'.format(v) if isinstance(v, Number) else v) for (k,v) in metadata.items()]\n",
    "    \n",
    "    # Sample plot\n",
    "    plot_data = pd.DataFrame({y_var+'_obs': Y_validate, y_var+'_pred': Y_pred})\n",
    "    \n",
    "    # week 7 raw\n",
    "    pl.plot(plot_data[(70*48):(77*48)])\n",
    "    pl.legend(plot_data.columns)\n",
    "    pl.show()\n",
    "    \n",
    "    # fornightly rolling mean\n",
    "    pl.plot(pd.rolling_mean(plot_data, window=14*48))\n",
    "    pl.legend(plot_data.columns)\n",
    "    pl.show()\n",
    "    \n",
    "    #daily cycle\n",
    "    pl.plot(plot_data.groupby(np.mod(plot_data.index, 48)).mean())\n",
    "    pl.legend(plot_data.columns)\n",
    "    pl.show()\n",
    "    \n",
    "    \n",
    "    return(metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "- insensitive to scaling or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(LinearRegression())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(StandardScaler(), LinearRegression())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(PCA(), LinearRegression())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(StandardScaler(), PCA(), LinearRegression())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "\n",
    "- Only a slight improvement\n",
    "    - because non-linearities are localised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PolynomialFeatures(5), LinearRegression())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "met_df_with_lag = pd.concat([met_df, met_df.diff()], axis=1).dropna()\n",
    "met_df_with_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(np.array(met_df_with_lag[:40000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flux_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flux_df[1:40001].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(LinearRegression())\n",
    "metadata.append(test_pipeline(pipe, X=met_df_with_lag[:40000], Y=flux_df[1:40001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "\n",
    "- very sensitive to scaling. Not sensitive to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(SGDRegressor())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(PCA(), SGDRegressor())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(StandardScaler(), PCA(), SGDRegressor())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_model(\"LogisticRegression\", LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_model(\"PassiveAggressiveRegressor\", PassiveAggressiveRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "- Sensitive to scaling, not to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(SVR())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVR())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(StandardScaler(), PCA(), SVR())\n",
    "#metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVR(kernel='poly'))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + ', poly kernel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(MultilayerPerceptronRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor())\n",
    "metadata.append(test_pipeline(pipe))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PCA(), MultilayerPerceptronRegressor())\n",
    "metadata.append(test_pipeline(pipe))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), MultilayerPerceptronRegressor())\n",
    "metadata.append(test_pipeline(pipe))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(activation='logistic'))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + ', logisitic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,20,)))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + \", [20,20,20]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,10,)))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + \", [10,10]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,30,)))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + \", [10,30]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,)))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + \", [20,20]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbours \n",
    "\n",
    "- Not sensitive to scaling or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(KNeighborsRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpld3.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PCA(), KNeighborsRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=1000))\n",
    "metadata.append(test_pipeline(pipe, get_pipeline_name(pipe) + \", 1000 neighbours\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(DecisionTreeRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ExtraTreesRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), ExtraTreesRegressor())\n",
    "metadata.append(test_pipeline(pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Metadata results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.DataFrame(metadata).set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import scipy\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import dblquad\n",
    "\n",
    "def mutual_info(x,y):\n",
    "    # Constants\n",
    "    MIN_DOUBLE = 4.9406564584124654e-324 \n",
    "                        # The minimum size of a Float64; used here to prevent the\n",
    "                        #  logarithmic function from hitting its undefined region\n",
    "                        #  at its asymptote of 0.\n",
    "    INF = float('inf')  # The floating-point representation for \"infinity\"\n",
    "\n",
    "    # x and y are previously defined as collections of \n",
    "    # floating point values with the same length\n",
    "\n",
    "    # Kernel estimation\n",
    "    gkde_x = gaussian_kde(x)\n",
    "    gkde_y = gaussian_kde(y)\n",
    "    gkde_xy = gaussian_kde([x,y])\n",
    "\n",
    "    mutual_info = lambda a,b: gkde_xy([a,b]) * \\\n",
    "               math.log((gkde_xy([a,b]) / (gkde_x(a) * gkde_y(b))) + MIN_DOUBLE)\n",
    "\n",
    "    # Compute MI(X,Y)\n",
    "    (minfo_xy, err_xy) = dblquad(mutual_info, -INF, INF, lambda a: 0, lambda a: INF)\n",
    "\n",
    "    print('minfo_xy = ', minfo_xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutual_info(met_df.SWdown, flux_df.Qh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "met_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data[0:30, 1] = np.random.rand(30) * iris.data[0:30, 1]\n",
    "X_train = iris.data[0:100, :2]\n",
    "Y_train = iris.data[0:100, 3]\n",
    "X_test = iris.data[100:150, :2]\n",
    "Y_test = iris.data[100:150, 3]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = LinearRegression(normalize=True)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE    raw: ', (np.mean((pred-Y_test)**2))**0.5)\n",
    "\n",
    "model.fit(scaler.fit_transform(X_train), Y_train)\n",
    "pred = model.predict(scaler.transform(X_test))\n",
    "\n",
    "print('RMSE scaled: ', (np.mean((pred-Y_test)**2))**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "print(X)\n",
    "print(list(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
