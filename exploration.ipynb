{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import xray\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "rcParams['figure.figsize'] = (14.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Perceptron, SGDRegressor, LogisticRegression, PassiveAggressiveRegressor\n",
    "from sklearn.svm import SVR, NuSVR  #, LinearSVR\n",
    "from sklearn.neural_network import MultilayerPerceptronRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_vars = ['SWdown', 'Tair', 'LWdown', 'Wind', 'Rainf', 'PSurf', 'Qair']\n",
    "met_data = xray.open_dataset('/home/naught101/phd/data/PALS/datasets/met/TumbaFluxnet.1.4_met.nc')\n",
    "met_df = met_data.to_dataframe().reset_index(['x','y','z']).ix[:, met_vars]\n",
    "\n",
    "flux_vars = ['Qh', 'Qle', 'Rnet', 'NEE']\n",
    "flux_data = xray.open_dataset('/home/naught101/phd/data/PALS/datasets/flux/TumbaFluxnet.1.4_flux.nc')\n",
    "flux_df = flux_data.to_dataframe().reset_index(['x','y']).ix[:, flux_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flux_df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "met_df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(f):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time.time()\n",
    "        print(f.__name__, 'took: {:2.4f} sec'.format(te-ts))        \n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def fit_pipeline(pipe, X, Y):\n",
    "    pipe.fit(X, Y)\n",
    "    \n",
    "    \n",
    "@timeit\n",
    "def get_pipeline_prediction(pipe, X):    \n",
    "    return(pipe.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_pipeline(name, pipe):\n",
    "    y_var = 'Qh'\n",
    "    X = met_df\n",
    "    Y = np.array(flux_df[y_var])\n",
    "    \n",
    "    train_len = (7*len(X)//10)\n",
    "    \n",
    "    X_train = X[:train_len]\n",
    "    X_validate = X[train_len:]\n",
    "    Y_train = Y[:train_len]\n",
    "    Y_validate = Y[train_len:]    \n",
    "    \n",
    "    print(name)\n",
    "    [print('\\t', k, ': ', v) for (k, v) in pipe.steps]\n",
    "    print('---')\n",
    "    fit_pipeline(pipe, X_train, Y_train)\n",
    "    Y_pred = get_pipeline_prediction(pipe, X_validate)\n",
    "    print('---')\n",
    "    print(Y_pred.shape)\n",
    "    if len(Y_pred.shape) > 1:\n",
    "        Y_pred = Y_pred[:,0]\n",
    "    print('RMSE: {:.2f}'.format(sqrt(mean((Y_pred-Y_validate)**2))))\n",
    "    plot_data = pd.DataFrame({y_var+'_obs': Y_validate[1:350], y_var+'_pred': Y_pred[1:350]}) \n",
    "    pl.plot(plot_data)\n",
    "    pl.legend(plot_data.columns)\n",
    "    pl.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pipeline(\"LinearRegression\", make_pipeline(LinearRegression()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LinearRegression())\n",
    "test_pipeline(\"LinearRegression\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PCA(), LinearRegression())\n",
    "test_pipeline(\"LinearRegression\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), LinearRegression())\n",
    "test_pipeline(\"LinearRegression\", pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SGDRegressor())\n",
    "test_pipeline(\"SGDRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDRegressor())\n",
    "test_pipeline(\"SGDRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PCA(), SGDRegressor())\n",
    "test_pipeline(\"SGDRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), SGDRegressor())\n",
    "test_pipeline(\"SGDRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_model(\"LogisticRegression\", LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_model(\"PassiveAggressiveRegressor\", PassiveAggressiveRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVR())\n",
    "test_pipeline(\"SVR - linear Support Vector Regression\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), SVR())\n",
    "test_pipeline(\"SVR - linear Support Vector Regression\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVR(kernel='poly'))\n",
    "test_pipeline(\"SVR - poly\", pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(MultilayerPerceptronRegressor())\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - default\", pipe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor())\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - default\", pipe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PCA(), MultilayerPerceptronRegressor())\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - default\", pipe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PCA(), MultilayerPerceptronRegressor())\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - default\", pipe)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(activation='logistic'))\n",
    "test_pipeline(\"MultilayerPerceptronRegressor- logistic\", pipe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,20,)))\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - 3 hidden layer\", pipe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,10,)))\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - 2 small hidden layer\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,30,)))\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - 2 small hidden layer\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,)))\n",
    "test_pipeline(\"MultilayerPerceptronRegressor - 2 small hidden layer\", pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "test_pipeline(\"KNeighborsRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=1000))\n",
    "test_pipeline(\"KNeighborsRegressor - 1000 neighbours\", pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(DecisionTreeRegressor())\n",
    "test_pipeline(\"DecisionTreeRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ExtraTreesRegressor())\n",
    "test_pipeline(\"ExtraTreesRegressor\", pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import scipy\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import dblquad\n",
    "\n",
    "def mutual_info(x,y):\n",
    "    # Constants\n",
    "    MIN_DOUBLE = 4.9406564584124654e-324 \n",
    "                        # The minimum size of a Float64; used here to prevent the\n",
    "                        #  logarithmic function from hitting its undefined region\n",
    "                        #  at its asymptote of 0.\n",
    "    INF = float('inf')  # The floating-point representation for \"infinity\"\n",
    "\n",
    "    # x and y are previously defined as collections of \n",
    "    # floating point values with the same length\n",
    "\n",
    "    # Kernel estimation\n",
    "    gkde_x = gaussian_kde(x)\n",
    "    gkde_y = gaussian_kde(y)\n",
    "    gkde_xy = gaussian_kde([x,y])\n",
    "\n",
    "    mutual_info = lambda a,b: gkde_xy([a,b]) * \\\n",
    "               math.log((gkde_xy([a,b]) / (gkde_x(a) * gkde_y(b))) + MIN_DOUBLE)\n",
    "\n",
    "    # Compute MI(X,Y)\n",
    "    (minfo_xy, err_xy) = dblquad(mutual_info, -INF, INF, lambda a: 0, lambda a: INF)\n",
    "\n",
    "    print('minfo_xy = ', minfo_xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutual_info(met_df.SWdown, flux_df.Qh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "met_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data[0:30, 1] = np.random.rand(30) * iris.data[0:30, 1]\n",
    "X_train = iris.data[0:100, :2]\n",
    "Y_train = iris.data[0:100, 3]\n",
    "X_test = iris.data[100:150, :2]\n",
    "Y_test = iris.data[100:150, 3]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = LinearRegression(normalize=True)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE    raw: ', (np.mean((pred-Y_test)**2))**0.5)\n",
    "\n",
    "model.fit(scaler.fit_transform(X_train), Y_train)\n",
    "pred = model.predict(scaler.transform(X_test))\n",
    "\n",
    "print('RMSE scaled: ', (np.mean((pred-Y_test)**2))**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
