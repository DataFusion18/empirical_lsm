# Model test bed

<<>>=
from run_models import fit_and_predict
from evaluate import full_evaluation
@

Cyclic train and test:

<<>>=
data_path = 'data/PALS/datasets'
datasets = ['Amplero', 'Blodgett', 'Bugac', 'ElSaler2', 'ElSaler', 'Espirra',
            'FortPeck', 'Harvard', 'Hesse', 'Howard', 'Howlandm', 'Hyytiala',
            'Kruger', 'Loobos', 'Merbleue', 'Mopane', 'Palang', 'Sylvania',
            'Tumba', 'UniMich']

met_paths = ['%s/met/%sFluxnet.1.4_met.nc' % (datapath, s) for s in datasets]
flux_paths = ['%s/flux/%sFluxnet.1.4_flux.nc' % (datapath, s) for s in datasets]

met_data = [xray.open_dataset(path) for path in met_paths]
flux_data = [xray.open_dataset(path) for path in flux_paths]
@

<<>>=
def test_pipeline_crossval(pipe, name, met_data, flux_data):
    assert isinstance(met_data, list), "Met data isn't a list"
    assert all([isinstance(m, xray.Dataset) for d in met_data]),
        "At least one met dataset isn't an xray dataset"
    assert isinstance(flux_data, list), "Flux data isn't a list"
    assert all([isinstance(m, xray.Dataset) for d in flux_data]),
        "At least one met dataset isn't an xray dataset"

    for i in len(met_dataset):
        met_train = [m for j, m in enumerate(met_data) if j != i]
        flux_train = [m for j, m in enumerate(flux_data) if j != i]
        met_test = met_data[i]
        flux_test = flux_data[i]

        fit_hash, fit_time = fit_pipe_multisite(pipe, name, met_train, flux_train)

        sim_data, pred_time = simulate_pipe_multisite(pipe, name, met_test)
        sim_hashes.append(sim_hash)

        eval_hash = evaluate_simulation(sim_data, flux_test, name)

        diagnostic_plots(sim_data, flux_data, name)
@


## Instantaneous models

pseudo code:
```
    set up pipeline
    set pipeline name
    for each site in sites:
        fit pipeline on other sites
        simulate site
        evaluate site
        store eval results
        ? print diagnostic plots
    collate eval results and print summary plots (PLUMBER plots/multisim plots)
```

### Linear regression
- insensitive to scaling or PCA

<<>>=
pipe = make_pipeline(LinearRegression())
name = get_pipeline_name(pipe)
@

### Polynomial regression
- Only a slight improvement
    - because non-linearities are localised?

<<>>=
pipe = make_pipeline(PolynomialFeatures(2), LinearRegression())
name = get_pipeline_name(pipe, "poly2")
@

<<>>=
pipe = make_pipeline(PolynomialFeatures(5), LinearRegression())
name = get_pipeline_name(pipe, "poly5")
@

### SGD
- very sensitive to scaling. Not sensitive to PCA

<<>>=
pipe = make_pipeline(StandardScaler(), SGDRegressor())
name = get_pipeline_name(pipe)
@

### Support Vector Machines
- Sensitive to scaling, not to PCA

<<>>=
pipe = make_pipeline(SVR())
name = get_pipeline_name(pipe)
test_pipeline(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), SVR())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), PCA(), SVR())
name = get_pipeline_name(pipe)
test_pipeline(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), SVR(kernel="poly"))
name = get_pipeline_name(pipe, "polykernel"))
@


### Multilayer Perceptron

<<>>=
pipe = make_pipeline(MultilayerPerceptronRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(PCA(), MultilayerPerceptronRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), PCA(), MultilayerPerceptronRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(activation="logistic"))
name = get_pipeline_name(pipe, "logisitic"))
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,20,)))
name = get_pipeline_name(pipe, "[20,20,20]"))
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,10,)))
name = get_pipeline_name(pipe, "[10,10]"))
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,30,)))
name = get_pipeline_name(pipe, "[10,30]"))
@

<<>>=
pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,)))
name = get_pipeline_name(pipe, "[20,20]"))
@


### K-nearest neighbours
- Not sensitive to scaling or PCA

<<>>=
pipe = make_pipeline(KNeighborsRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors = 1000))
name = get_pipeline_name(pipe, "1000 neighbours")
@


### Decision Trees

<<>>=
pipe = make_pipeline(DecisionTreeRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(ExtraTreesRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), PCA(), ExtraTreesRegressor())
name = get_pipeline_name(pipe)
@


### Lagged linear regression

- need to make a proper wrapper for this.

<<>>=
pipe = make_pipeline(LagFeatures(), LinearRegression())
name = name=get_pipeline_name(pipe, "lag1"))
@


### Markov lagging

- use one timestep's output as an input for the next timestep


PLUMBER plots/intercomparison
=============================


