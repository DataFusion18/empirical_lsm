% Model test bed
% ned haughton
% <%from datetime import datetime as dt
print(dt.isoformat(dt.now(), sep=' '))%>

<<>>=
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.preprocessing import PolynomialFeatures
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline

from ubermodel.models import get_pipeline_name, test_pipeline_crossval, fit_pipe_multisite, \
                             simulate_pipe
from ubermodel.data import get_met_datasets, get_flux_datasets
# from ubermodel.models import fit_pipe_multisite, simulate_pipe_multisite
from ubermodel.evaluate import evaluate_simulation
@

Cyclic train and test:

<<>>=
met_data = get_met_datasets()
flux_data = get_flux_datasets()
@

<<>>=
def diagnostic_plots(sim_data, flux_data, name):
    pass
@


## Instantaneous models

pseudo code:
```
    set up pipeline
    set pipeline name
    for each site in sites:
        fit pipeline on other sites
        simulate site
        evaluate site
        store eval results
        ? print diagnostic plots
    collate eval results and print summary plots (PLUMBER plots/multisim plots)
```

### Linear regression
- insensitive to scaling or PCA

<<>>=
from sklearn.linear_model import LinearRegression

pipe = make_pipeline(LinearRegression())
name = get_pipeline_name(pipe)

test_pipeline_crossval(pipe, name, met_data, flux_data)
@

### Polynomial regression
- Only a slight improvement
    - because non-linearities are localised?

<<>>=
from sklearn.preprocessing import PolynomialFeatures

pipe = make_pipeline(PolynomialFeatures(2), LinearRegression())
name = get_pipeline_name(pipe, "poly2")
@

<<>>=
pipe = make_pipeline(PolynomialFeatures(5), LinearRegression())
name = get_pipeline_name(pipe, "poly5")
@

### SGD
- very sensitive to scaling. Not sensitive to PCA

<<>>=
from sklearn.linear_model import SGDRegressor

pipe = make_pipeline(StandardScaler(), SGDRegressor())
name = get_pipeline_name(pipe)
@

### Support Vector Machines
- Sensitive to scaling, not to PCA

<<>>=
from sklearn.svm import SVR

pipe = make_pipeline(SVR())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), SVR())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), PCA(), SVR())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), SVR(kernel="poly"))
name = get_pipeline_name(pipe, "polykernel")
@


### Multilayer Perceptron

<<>>=
# from sklearn.neural_network import MultilayerPerceptronRegressor
#
# pipe = make_pipeline(MultilayerPerceptronRegressor())
# name = get_pipeline_name(pipe)
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor())
# name = get_pipeline_name(pipe)
# @
#
# <<>>=
# pipe = make_pipeline(PCA(), MultilayerPerceptronRegressor())
# name = get_pipeline_name(pipe)
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), PCA(), MultilayerPerceptronRegressor())
# name = get_pipeline_name(pipe)
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(activation="logistic"))
# name = get_pipeline_name(pipe, "logisitic")
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,20,)))
# name = get_pipeline_name(pipe, "[20,20,20]")
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,10,)))
# name = get_pipeline_name(pipe, "[10,10]")
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(10,30,)))
# name = get_pipeline_name(pipe, "[10,30]")
# @
#
# <<>>=
# pipe = make_pipeline(StandardScaler(), MultilayerPerceptronRegressor(hidden_layer_sizes=(20,20,)))
# name = get_pipeline_name(pipe, "[20,20]")
@


### K-nearest neighbours
- Not sensitive to scaling or PCA

<<>>=
from sklearn.neighbors import KNeighborsRegressor

pipe = make_pipeline(KNeighborsRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors = 1000))
name = get_pipeline_name(pipe, "1000 neighbours")
@


### Decision Trees

<<>>=
from sklearn.tree import DecisionTreeRegressor

pipe = make_pipeline(DecisionTreeRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
from sklearn.ensemble import ExtraTreesRegressor

pipe = make_pipeline(ExtraTreesRegressor())
name = get_pipeline_name(pipe)
@

<<>>=
pipe = make_pipeline(StandardScaler(), PCA(), ExtraTreesRegressor())
name = get_pipeline_name(pipe)
@


### Lagged linear regression

- need to make a proper wrapper for this.

<<>>=
#pipe = make_pipeline(LagFeatures(), LinearRegression())
#name = get_pipeline_name(pipe, "lag1")
@


### Markov lagging

- use one timestep's output as an input for the next timestep


PLUMBER plots/intercomparison
=============================


